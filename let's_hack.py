# -*- coding: utf-8 -*-
"""Let's_hack.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1InBB6aa802TkIla79ZUiY6N7cyt5GuLg
"""

# Load libraries
import pandas as pd
import numpy as np
from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier
from sklearn.model_selection import train_test_split # Import train_test_split function
from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import  RandomizedSearchCV
from sklearn.preprocessing import StandardScaler, MinMaxScaler
#from sklearn.model_selection import ParameterGrid

"""**Data Source : Harvard Dataverse**"""

data = pd.read_csv("https://docs.google.com/spreadsheets/d/e/2PACX-1vRnYyLxWaZXv7VsWecmdFS3c9GE62rqYpXuxPxEf-uxJmBilt78oH1xGmz2EBZBB_QY5BE4Ldsd74Td/pub?output=csv")
feature_cols = ['N', 'P', 'K', 'temperature','humidity','ph','rainfall']
X = data[feature_cols] # Features
y = data.label # Target variable

# Split the train dataset into training set and validation set
X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.15, random_state=42) # 80% training and 20% test
X_train, X_val, y_train, y_val = train_test_split (X_trainval, y_trainval, test_size=0.15/0.85, random_state=42)

# standardize the dataset
scaler = StandardScaler()
X_train_std = scaler.fit_transform(X_train)
X_val_std = scaler.transform(X_val)
X_test_std = scaler.transform(X_test)

#Building Random Forest Classification model using Scikit-learn.

rf = RandomForestClassifier(random_state=42, n_estimators=100)
# Train Random Forest Classification model
rf.fit (X_train_std, y_train)

#Validation
param_grid = {
    'n_estimators': np.arange(10, 20),
    'max_depth': np.arange(1, 20),
    'min_samples_split': np.arange(2, 15),
    'min_samples_leaf': np.arange(1, 15)
}


# perform hyperparameter tuning using randomized search cross-validation
rf_random = RandomizedSearchCV(estimator=rf, param_distributions=param_grid, n_iter=100, cv=3, verbose=2, random_state=42, n_jobs=-1)
rf_random.fit(X_train_std, y_train)

# print the best hyperparameters found during tuning
print("Best Hyperparameters:", rf_random.best_params_)

rf_best = RandomForestClassifier(n_estimators=rf_random.best_params_['n_estimators'],
                                  max_depth=rf_random.best_params_['max_depth'],
                                  min_samples_split=rf_random.best_params_['min_samples_split'],
                                  min_samples_leaf=rf_random.best_params_['min_samples_leaf'])
rf_best.fit(X_train_std, y_train)

#Training accuracy
y_train_pred = rf_best.predict(X_train_std)
train_accuracy = metrics.accuracy_score(y_train, y_train_pred)

# Calculate validation accuracy
y_val_pred = rf_best.predict(X_val_std)
val_accuracy = metrics.accuracy_score(y_val, y_val_pred)



print(f"Training accuracy: {train_accuracy:.4f}")
print(f"Validation accuracy: {val_accuracy:.4f}")
#conf_mat = confusion_matrix(y_test, y_pred_validated)
#print("Confusion Matrix:\n", conf_mat)"""

# TEST SET PERFORMANCE
# Combine the training and validation data
# To use the tuned rf_best model on real-world data, you would need to fit it on the entire dataset, including both the training and validation data
# -> Make predictions on new, unseen data.
X_train_full = np.concatenate((X_train_std, X_val_std), axis=0)
y_train_full = np.concatenate((y_train, y_val), axis=0)

# Fit the rf_best model on the entire dataset
rf_best_full = RandomForestClassifier (random_state = 42, max_depth=9, min_samples_leaf=10, min_samples_split= 8, n_estimators=15)
rf_best_full.fit(X_train_full, y_train_full)

# Make predictions on the test data using the tuned rf_best_full model
y_test_pred = rf_best_full.predict(X_test_std)

# Calculate the test accuracy
test_accuracy = metrics.accuracy_score(y_test, y_test_pred)
print("Test Accuracy:", test_accuracy)





"""Vizualizing decision trees"""

from sklearn.tree import export_graphviz

from six import StringIO

from IPython.display import Image
import pydotplus

dot_data = StringIO()
export_graphviz(tree, out_file=dot_data,
                filled=True, rounded=True,
                special_characters=True,feature_names = feature_cols,class_names=['rice','maize', 'Soyabeans', 'beans', 'peas', 'groundnuts', 'cowpeas', 'banana', 'mango', 'grapes', 'watermelon', 'apple', 'orange', 'cotton', 'coffee'])
graph = pydotplus.graph_from_dot_data(dot_data.getvalue())
graph.write_png('crops.png')
Image(graph.create_png())

#trying to test with user input
'N', 'P', 'K', 'temperature','humidity','ph','rainfall'
n =input("Enter the Nitrogen amount (0 to 250) in your soil __")
p = input("Enter the potassium amount (0 to 250) in your soil __")
k =input("Enter the phosphorous amount (0 to 250) in your soil __")
temperature =input("Enter the average annual temperature for this year ( degree celcius) 0 to 100 __")
humidity =input("Enter the humidity of the region (0 to 100) __")
ph =input("Enter the ph (Strength of Hydrogen) of your soil (0 to 14) __")
rainfall =input("Enter the annual rainfall in mm (0 to 1000) __")

# Make a prediction for a single test case
set_test = [n,p,k,temperature,humidity,ph,rainfall]  # example test case
Prediction_result = rf_model_on_full_data.predict([set_test])

# Print the predicted class
print("Your suggested main plant is: {}". format(Prediction_result))



"""Using ***OpenAI API*** to provide crop Manual."""

api_key = "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"

#installing packages
!pip install openai
import openai
openai.api_key = api_key

## USer can set a prompt for a question
prompt = input("sample_prompt")
"""prompt = '''
You are a farmer in Nepal. You have been farming for the last 20 years. You are a crop researcher. Answer based on your expertise.

Q: How to grow rice? Give step wise instructions.
A:
'''"""
response = openai.Completion.create(
  model="text-davinci-003",
  prompt=prompt,
  temperature=0.3,
  max_tokens=60,
  frequency_penalty=0.0,
  presence_penalty=0.0
)

responseText = response.choices[0].text

print(responseText)

!pip install langchain
!pip install google-search-results

import os
os.environ['SERPAPI_API_KEY'] = "5aec2d6745b84d687ad9d0ee28c9577f00f71d53d996fab7fe2399bc08e90277"

from langchain.agents import load_tools
from langchain.agents import initialize_agent
from langchain.llms import OpenAI
llm = OpenAI(temperature=0, openai_api_key=api_key)
tools = load_tools(["serpapi", "llm-math"], llm=llm)
agent = initialize_agent(tools, llm, agent="zero-shot-react-description", verbose=True)

label = Prediction_result # This is from the previous program. An example might be "rice" or "maize" or "apple".
#This prepares a manual for the users
print("Crop Manual")
print("How to grow " + label)
agent.run("How to grow "+ label + "? Give step wise instructions in a very clear and simple language as if you are explaining a farmer.")
print("How to preserve "+ label+ " from pests?")
agent.run("How to preserve "+ label+ " from pests?")
print("How much water does " + label + " needs, and how often should it be watered?")
agent.run("How much water does " + label + " needs, and how often should it be watered?")
print("What kind of sunlight and temperature conditions are best for "+ label)
agent.run("What kind of sunlight and temperature conditions are best for "+ label)
print("Does "+ label+  " require any special pruning, fertilization, or other care?")
agent.run("Does"+ label+  "require any special pruning, fertilization, or other care?")
print("How long does it typically take for "+ label+ " to mature and be ready for harvest?")
agent.run("How long does it typically take for "+ label+ " to mature and be ready for harvest?")
#This is a place user can ask their own questions.
question = input("Do you have any confusions?")
agent.run(question)

"""**Genetic Algorithm for Crop Compatibility**





"""

import random

# define the objectives and their weights
objectives = ["yield", "resource_use_efficiency", "competition", "pest_and_disease_resistance", "nutrient_uptake", "environmental_compatibility"]
weights = [0.2, 0.2, 0.15, 0.15, 0.15, 0.15]

# define the range of compatibility levels for each objective
ranges = {
    "yield": [0, 10],
    "resource_use_efficiency": [0, 1],
    "competition": [0, 1],
    "pest_and_disease_resistance": [0, 1],
    "nutrient_uptake": [0, 1],
    "environmental_compatibility": [0, 1]
}

# define the number of chromosomes and iterations for the genetic algorithm
num_chromosomes = 100
num_iterations = 100

# define the fitness function
def fitness(chromosome):
    total_score = 0
    for i in range(len(chromosome)):
        total_score += chromosome[i] * weights[i]
    return total_score

# define the crossover function
def crossover(parent1, parent2):
    child = []
    for i in range(len(parent1)):
        if random.random() < 0.5:
            child.append(parent1[i])
        else:
            child.append(parent2[i])
    return child

# define the mutation function
def mutate(chromosome):
    for i in range(len(chromosome)):
        if random.random() < 0.1:
            chromosome[i] = random.uniform(ranges[objectives[i]][0], ranges[objectives[i]][1])
    return chromosome

# initialize the population
population = []
for i in range(num_chromosomes):
    chromosome = []
    for j in range(len(objectives)):
        chromosome.append(random.uniform(ranges[objectives[j]][0], ranges[objectives[j]][1]))
    population.append(chromosome)

# run the genetic algorithm
for i in range(num_iterations):
    # calculate the fitness of each chromosome
    fitness_scores = []
    for chromosome in population:
        fitness_scores.append(fitness(chromosome))

    # select the parents for crossover
    parents = []
    for j in range(2):
        max_fitness_index = fitness_scores.index(max(fitness_scores))
        parents.append(population[max_fitness_index])
        fitness_scores.pop(max_fitness_index)
        population.pop(max_fitness_index)

    # perform crossover and mutation to generate new children
    children = []
    for j in range(num_chromosomes - 2):
        child = crossover(parents[0], parents[1])
        child = mutate(child)
        children.append(child)

    # add the parents back into the population
    population += parents

    # add the new children to the population
    population += children

# find the best chromosome and its fitness score
best_chromosome = population[0]
best_fitness = fitness(best_chromosome)
for chromosome in population:
    chromosome_fitness = fitness(chromosome)
    if chromosome_fitness > best_fitness:
        best_chromosome = chromosome
        best_fitness = chromosome_fitness

# print the results
print("Best compatibility level for the two crops:")
for i in range(len(objectives)):
    print(f"{objectives[i]}: {best_chromosome[i]}")
print(f"Fitness score: {best_fitness}")

print("Thank you for using the model")

"""# Thank you!"""
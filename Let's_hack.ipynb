{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwSi6rkuQ1Yg"
      },
      "outputs": [],
      "source": [
        "# Load libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
        "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
        "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import  RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "#from sklearn.model_selection import ParameterGrid\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhVxNA_mTOuB"
      },
      "source": [
        "**Data Source : Harvard Dataverse**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2z-5BsvAtWPZ"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"https://docs.google.com/spreadsheets/d/e/2PACX-1vRnYyLxWaZXv7VsWecmdFS3c9GE62rqYpXuxPxEf-uxJmBilt78oH1xGmz2EBZBB_QY5BE4Ldsd74Td/pub?output=csv\")\n",
        "feature_cols = ['N', 'P', 'K', 'temperature','humidity','ph','rainfall']\n",
        "X = data[feature_cols] # Features\n",
        "y = data.label # Target variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0nc9i1vUeS7"
      },
      "outputs": [],
      "source": [
        "# Split the train dataset into training set and validation set\n",
        "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.15, random_state=42) # 80% training and 20% test\n",
        "X_train, X_val, y_train, y_val = train_test_split (X_trainval, y_trainval, test_size=0.15/0.85, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# standardize the dataset\n",
        "scaler = StandardScaler()\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_val_std = scaler.transform(X_val)\n",
        "X_test_std = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "Ab8ToCLX75ZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Building Random Forest Classification model using Scikit-learn.\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42, n_estimators=100)\n",
        "# Train Random Forest Classification model\n",
        "rf.fit (X_train_std, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "tc7Wt1b29b4w",
        "outputId": "1ea7f403-6f1e-4d4e-d773-add75e2cc4bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiV537FJHSwf",
        "outputId": "b21044af-7c03-4459-b260-1b8f26f958d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
            "Best Hyperparameters: {'n_estimators': 15, 'min_samples_split': 8, 'min_samples_leaf': 10, 'max_depth': 9}\n",
            "Training accuracy: 1.0000\n",
            "Validation accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "#Validation\n",
        "param_grid = {\n",
        "    'n_estimators': np.arange(10, 20),\n",
        "    'max_depth': np.arange(1, 20),\n",
        "    'min_samples_split': np.arange(2, 15),\n",
        "    'min_samples_leaf': np.arange(1, 15)\n",
        "}\n",
        "\n",
        "\n",
        "# perform hyperparameter tuning using randomized search cross-validation\n",
        "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=param_grid, n_iter=100, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
        "rf_random.fit(X_train_std, y_train)\n",
        "\n",
        "# print the best hyperparameters found during tuning\n",
        "print(\"Best Hyperparameters:\", rf_random.best_params_)\n",
        "\n",
        "rf_best = RandomForestClassifier(n_estimators=rf_random.best_params_['n_estimators'],\n",
        "                                  max_depth=rf_random.best_params_['max_depth'],\n",
        "                                  min_samples_split=rf_random.best_params_['min_samples_split'],\n",
        "                                  min_samples_leaf=rf_random.best_params_['min_samples_leaf'])\n",
        "rf_best.fit(X_train_std, y_train)\n",
        "\n",
        "#Training accuracy\n",
        "y_train_pred = rf_best.predict(X_train_std)\n",
        "train_accuracy = metrics.accuracy_score(y_train, y_train_pred)\n",
        "\n",
        "# Calculate validation accuracy\n",
        "y_val_pred = rf_best.predict(X_val_std)\n",
        "val_accuracy = metrics.accuracy_score(y_val, y_val_pred)\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Training accuracy: {train_accuracy:.4f}\")\n",
        "print(f\"Validation accuracy: {val_accuracy:.4f}\")\n",
        "#conf_mat = confusion_matrix(y_test, y_pred_validated)\n",
        "#print(\"Confusion Matrix:\\n\", conf_mat)\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYEP15HuUeZX",
        "outputId": "5fbf0e46-64fe-4c29-ee72-df6eff64d6d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "# TEST SET PERFORMANCE\n",
        "# Combine the training and validation data\n",
        "# To use the tuned rf_best model on real-world data, you would need to fit it on the entire dataset, including both the training and validation data\n",
        "# -> Make predictions on new, unseen data.\n",
        "X_train_full = np.concatenate((X_train_std, X_val_std), axis=0)\n",
        "y_train_full = np.concatenate((y_train, y_val), axis=0)\n",
        "\n",
        "# Fit the rf_best model on the entire dataset\n",
        "rf_best_full = RandomForestClassifier (random_state = 42, max_depth=9, min_samples_leaf=10, min_samples_split= 8, n_estimators=15)\n",
        "rf_best_full.fit(X_train_full, y_train_full)\n",
        "\n",
        "# Make predictions on the test data using the tuned rf_best_full model\n",
        "y_test_pred = rf_best_full.predict(X_test_std)\n",
        "\n",
        "# Calculate the test accuracy\n",
        "test_accuracy = metrics.accuracy_score(y_test, y_test_pred)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktOoBA_m9MO4"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qXNWSzyUebx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTB8BJHjvzMw"
      },
      "source": [
        "Vizualizing decision trees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "X5hPoR1UUeeb",
        "outputId": "3871d047-237a-4e1b-f898-dd04477af513"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-9e6363bc3443>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdot_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m export_graphviz(tree, out_file=dot_data,  \n\u001b[0m\u001b[1;32m     10\u001b[0m                 \u001b[0mfilled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrounded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 special_characters=True,feature_names = feature_cols,class_names=['rice','maize', 'Soyabeans', 'beans', 'peas', 'groundnuts', 'cowpeas', 'banana', 'mango', 'grapes', 'watermelon', 'apple', 'orange', 'cotton', 'coffee'])\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tree' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "from sklearn.tree import export_graphviz\n",
        "\n",
        "from six import StringIO\n",
        "\n",
        "from IPython.display import Image\n",
        "import pydotplus\n",
        "\n",
        "dot_data = StringIO()\n",
        "export_graphviz(tree, out_file=dot_data,\n",
        "                filled=True, rounded=True,\n",
        "                special_characters=True,feature_names = feature_cols,class_names=['rice','maize', 'Soyabeans', 'beans', 'peas', 'groundnuts', 'cowpeas', 'banana', 'mango', 'grapes', 'watermelon', 'apple', 'orange', 'cotton', 'coffee'])\n",
        "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
        "graph.write_png('crops.png')\n",
        "Image(graph.create_png())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "6U3udAXGUek5",
        "outputId": "db34e025-8e3e-4aba-9036-14d6a76140c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the Nitrogen amount (0 to 250) in your soil __5\n",
            "Enter the potassium amount (0 to 250) in your soil __5\n",
            "Enter the phosphorous amount (0 to 250) in your soil __5\n",
            "Enter the average annual temperature for this year ( degree celcius) 0 to 100 __5\n",
            "Enter the humidity of the region (0 to 100) __5\n",
            "Enter the ph (Strength of Hydrogen) of your soil (0 to 14) __5\n",
            "Enter the annual rainfall in mm (0 to 1000) __5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-2afafd3e3e93>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Make a prediction for a single test case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mset_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhumidity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrainfall\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# example test case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mPrediction_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf_model_on_full_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mset_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Print the predicted class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'rf_model_on_full_data' is not defined"
          ]
        }
      ],
      "source": [
        "#trying to test with user input\n",
        "'N', 'P', 'K', 'temperature','humidity','ph','rainfall'\n",
        "n =input(\"Enter the Nitrogen amount (0 to 250) in your soil __\")\n",
        "p = input(\"Enter the potassium amount (0 to 250) in your soil __\")\n",
        "k =input(\"Enter the phosphorous amount (0 to 250) in your soil __\")\n",
        "temperature =input(\"Enter the average annual temperature for this year ( degree celcius) 0 to 100 __\")\n",
        "humidity =input(\"Enter the humidity of the region (0 to 100) __\")\n",
        "ph =input(\"Enter the ph (Strength of Hydrogen) of your soil (0 to 14) __\")\n",
        "rainfall =input(\"Enter the annual rainfall in mm (0 to 1000) __\")\n",
        "\n",
        "# Make a prediction for a single test case\n",
        "set_test = [n,p,k,temperature,humidity,ph,rainfall]  # example test case\n",
        "Prediction_result = rf_model_on_full_data.predict([set_test])\n",
        "\n",
        "# Print the predicted class\n",
        "print(\"Your suggested main plant is: {}\". format(Prediction_result))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNd-OFxt-kYJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8N0wN3Wjbzp"
      },
      "source": [
        "Using ***OpenAI API*** to provide crop Manual."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwCV4Z1TkPKI"
      },
      "outputs": [],
      "source": [
        "api_key = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpDRhMLukVkR",
        "outputId": "6278cf8a-9542-4c7b-a5de-20977194eedc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.26.5.tar.gz (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 KB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.8/dist-packages (from openai) (2.25.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (3.0.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.8.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.26.5-py3-none-any.whl size=67620 sha256=eef3ca312534cc744fc02e74e54a39493f344628cd735738ee8ad5c7b42714e7\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/47/99/8273a59fbd59c303e8ff175416d5c1c9c03a2e83ebf7525a99\n",
            "Successfully built openai\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.26.5\n"
          ]
        }
      ],
      "source": [
        "#installing packages\n",
        "!pip install openai\n",
        "import openai\n",
        "openai.api_key = api_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W94OeWvUkXaV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "outputId": "ebfb4b39-f53a-4ef7-cc9d-4e2e9e2cd99e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "APIError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAPIError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-4e47692c72c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m '''\n\u001b[0;32m----> 9\u001b[0;31m response = openai.Completion.create(\n\u001b[0m\u001b[1;32m     10\u001b[0m  \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text-davinci-003\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m  \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/openai/api_resources/completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         )\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    617\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m             return (\n\u001b[0;32m--> 619\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    620\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    680\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m             )\n",
            "\u001b[0;31mAPIError\u001b[0m: Internal server error {\n    \"error\": {\n        \"message\": \"Internal server error\",\n        \"type\": \"auth_subrequest_error\",\n        \"param\": null,\n        \"code\": \"internal_error\"\n    }\n}\n 500 {'error': {'message': 'Internal server error', 'type': 'auth_subrequest_error', 'param': None, 'code': 'internal_error'}} {'Date': 'Tue, 21 Feb 2023 07:17:50 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '166', 'Connection': 'keep-alive', 'Vary': 'Origin', 'X-Request-Id': '73594a62eedf7a90b9c1ac04e1fa4c0f', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains'}"
          ]
        }
      ],
      "source": [
        " ## USer can set a prompt for a question\n",
        "prompt = input(\"sample_prompt\")\n",
        "\"\"\"prompt = '''\n",
        "You are a farmer in Nepal. You have been farming for the last 20 years. You are a crop researcher. Answer based on your expertise.\n",
        "\n",
        "Q: How to grow rice? Give step wise instructions.\n",
        "A:\n",
        "'''\"\"\"\n",
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-003\",\n",
        "  prompt=prompt,\n",
        "  temperature=0.3,\n",
        "  max_tokens=60,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0\n",
        ")\n",
        "\n",
        "responseText = response.choices[0].text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOwq0dCWkzal"
      },
      "outputs": [],
      "source": [
        "print(responseText)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JmmbWpnl0qj"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install google-search-results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHLp1YEjl0xQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['SERPAPI_API_KEY'] = \"5aec2d6745b84d687ad9d0ee28c9577f00f71d53d996fab7fe2399bc08e90277\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVh-YLhjl0zp"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.llms import OpenAI\n",
        "llm = OpenAI(temperature=0, openai_api_key=api_key)\n",
        "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
        "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2D2U-3r8l02E"
      },
      "outputs": [],
      "source": [
        "label = Prediction_result # This is from the previous program. An example might be \"rice\" or \"maize\" or \"apple\".\n",
        "#This prepares a manual for the users\n",
        "print(\"Crop Manual\")\n",
        "print(\"How to grow \" + label)\n",
        "agent.run(\"How to grow \"+ label + \"? Give step wise instructions in a very clear and simple language as if you are explaining a farmer.\")\n",
        "print(\"How to preserve \"+ label+ \" from pests?\")\n",
        "agent.run(\"How to preserve \"+ label+ \" from pests?\")\n",
        "print(\"How much water does \" + label + \" needs, and how often should it be watered?\")\n",
        "agent.run(\"How much water does \" + label + \" needs, and how often should it be watered?\")\n",
        "print(\"What kind of sunlight and temperature conditions are best for \"+ label)\n",
        "agent.run(\"What kind of sunlight and temperature conditions are best for \"+ label)\n",
        "print(\"Does \"+ label+  \" require any special pruning, fertilization, or other care?\")\n",
        "agent.run(\"Does\"+ label+  \"require any special pruning, fertilization, or other care?\")\n",
        "print(\"How long does it typically take for \"+ label+ \" to mature and be ready for harvest?\")\n",
        "agent.run(\"How long does it typically take for \"+ label+ \" to mature and be ready for harvest?\")\n",
        "#This is a place user can ask their own questions.\n",
        "question = input(\"Do you have any confusions?\")\n",
        "agent.run(question)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8tA5S9KnHrW"
      },
      "source": [
        "**Genetic Algorithm for Crop Compatibility**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIpSnrMY2Lgz"
      },
      "outputs": [],
      "source": [
        "\n",
        "import random\n",
        "\n",
        "# define the objectives and their weights\n",
        "objectives = [\"yield\", \"resource_use_efficiency\", \"competition\", \"pest_and_disease_resistance\", \"nutrient_uptake\", \"environmental_compatibility\"]\n",
        "weights = [0.2, 0.2, 0.15, 0.15, 0.15, 0.15]\n",
        "\n",
        "# define the range of compatibility levels for each objective\n",
        "ranges = {\n",
        "    \"yield\": [0, 10],\n",
        "    \"resource_use_efficiency\": [0, 1],\n",
        "    \"competition\": [0, 1],\n",
        "    \"pest_and_disease_resistance\": [0, 1],\n",
        "    \"nutrient_uptake\": [0, 1],\n",
        "    \"environmental_compatibility\": [0, 1]\n",
        "}\n",
        "\n",
        "# define the number of chromosomes and iterations for the genetic algorithm\n",
        "num_chromosomes = 100\n",
        "num_iterations = 100\n",
        "\n",
        "# define the fitness function\n",
        "def fitness(chromosome):\n",
        "    total_score = 0\n",
        "    for i in range(len(chromosome)):\n",
        "        total_score += chromosome[i] * weights[i]\n",
        "    return total_score\n",
        "\n",
        "# define the crossover function\n",
        "def crossover(parent1, parent2):\n",
        "    child = []\n",
        "    for i in range(len(parent1)):\n",
        "        if random.random() < 0.5:\n",
        "            child.append(parent1[i])\n",
        "        else:\n",
        "            child.append(parent2[i])\n",
        "    return child\n",
        "\n",
        "# define the mutation function\n",
        "def mutate(chromosome):\n",
        "    for i in range(len(chromosome)):\n",
        "        if random.random() < 0.1:\n",
        "            chromosome[i] = random.uniform(ranges[objectives[i]][0], ranges[objectives[i]][1])\n",
        "    return chromosome\n",
        "\n",
        "# initialize the population\n",
        "population = []\n",
        "for i in range(num_chromosomes):\n",
        "    chromosome = []\n",
        "    for j in range(len(objectives)):\n",
        "        chromosome.append(random.uniform(ranges[objectives[j]][0], ranges[objectives[j]][1]))\n",
        "    population.append(chromosome)\n",
        "\n",
        "# run the genetic algorithm\n",
        "for i in range(num_iterations):\n",
        "    # calculate the fitness of each chromosome\n",
        "    fitness_scores = []\n",
        "    for chromosome in population:\n",
        "        fitness_scores.append(fitness(chromosome))\n",
        "\n",
        "    # select the parents for crossover\n",
        "    parents = []\n",
        "    for j in range(2):\n",
        "        max_fitness_index = fitness_scores.index(max(fitness_scores))\n",
        "        parents.append(population[max_fitness_index])\n",
        "        fitness_scores.pop(max_fitness_index)\n",
        "        population.pop(max_fitness_index)\n",
        "\n",
        "    # perform crossover and mutation to generate new children\n",
        "    children = []\n",
        "    for j in range(num_chromosomes - 2):\n",
        "        child = crossover(parents[0], parents[1])\n",
        "        child = mutate(child)\n",
        "        children.append(child)\n",
        "\n",
        "    # add the parents back into the population\n",
        "    population += parents\n",
        "\n",
        "    # add the new children to the population\n",
        "    population += children\n",
        "\n",
        "# find the best chromosome and its fitness score\n",
        "best_chromosome = population[0]\n",
        "best_fitness = fitness(best_chromosome)\n",
        "for chromosome in population:\n",
        "    chromosome_fitness = fitness(chromosome)\n",
        "    if chromosome_fitness > best_fitness:\n",
        "        best_chromosome = chromosome\n",
        "        best_fitness = chromosome_fitness\n",
        "\n",
        "# print the results\n",
        "print(\"Best compatibility level for the two crops:\")\n",
        "for i in range(len(objectives)):\n",
        "    print(f\"{objectives[i]}: {best_chromosome[i]}\")\n",
        "print(f\"Fitness score: {best_fitness}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kb1sbjtyqbMS"
      },
      "outputs": [],
      "source": [
        "print(\"Thank you for using the model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vE7TlGZ-qbiu"
      },
      "source": [
        "# Thank you!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}